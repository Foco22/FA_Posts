{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAGAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install ragas\n",
    "%pip install langchain langchain-openai langchain-core langgraph openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Python Version**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La version de python debe ser mayor a 3.1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Librerias**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Annotated, Literal, TypedDict\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, ToolMessage, BaseMessage, AIMessage\n",
    "from langchain_core.tools import Tool\n",
    "from langgraph.graph import StateGraph, MessagesState\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langchain.callbacks.tracers import LangChainTracer\n",
    "from agent.states import StatusMessagesState\n",
    "from langchain.schema import HumanMessage, SystemMessage, AIMessage\n",
    "# For LangChain Community (newer versions):\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
    "\n",
    "# For OpenAI-style messages:\n",
    "from openai.types.chat import ChatCompletionMessage\n",
    "from agent.prompts import SYSTEM_MESSAGE\n",
    "from agent.agent import build_graph\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LangGraph**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your OpenAI API key\n",
    "\n",
    "## Incluye tu API key de OpenAI en la variable de entorno\n",
    "## Incluye tu API key de LangChain en la variable de entorno. No es esencial, pero es recomendable\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = \"\"\n",
    "## add langsmith\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"arithmetic\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>result</th>\n",
       "      <th>tool_calls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cual es el resultado de (1645+1223)/344</td>\n",
       "      <td>El resultado de la operacion es el siguiente: ...</td>\n",
       "      <td>[name='sum' args={'__arg1': 1645, '__arg2': 12...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  question  \\\n",
       "0  Cual es el resultado de (1645+1223)/344   \n",
       "\n",
       "                                              result  \\\n",
       "0  El resultado de la operacion es el siguiente: ...   \n",
       "\n",
       "                                          tool_calls  \n",
       "0  [name='sum' args={'__arg1': 1645, '__arg2': 12...  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_json = {\n",
    "    'question': 'Cual es el resultado de (1645+1223)/344',\n",
    "    'result': 'El resultado de la operacion es el siguiente: 8.34',\n",
    "    'tool_calls': [\n",
    "        ToolCall(name=\"sum\", args={\"__arg1\": 1645, \"__arg2\": 1223}),\n",
    "        ToolCall(name=\"divide\", args={\"__arg1\": 2868, \"__arg2\": 344})\n",
    "    ]\n",
    "}\n",
    "df = pd.DataFrame([results_json])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Call Agents**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Chatbot node: Processing messages...\n",
      "System message content: You are a helpful assistant that can perform basic arithmetic operations.\n",
      "\n",
      "Key capabilities:\n",
      "- Perform multiplication\n",
      "- Perform division\n",
      "- Perform addition\n",
      "- Perform subtraction\n",
      "\n",
      "The tool you should use is:\n",
      "- multiply: Multiplies two numbers. The arguments should be passed as 'a' and 'b'. Must not be like arg1: 2422*6454656\n",
      "- divide: Divides two numbers. The arguments should be passed as 'a' and 'b'. Must not be like arg1: 2422/6454656\n",
      "- sum: Sums two numbers. The arguments should be passed as 'a' and 'b'. Must not be like arg1: 2422+6454656\n",
      "- sub: Subtracts two numbers. The arguments should be passed as 'a' and 'b'. Must not be like arg1: 2422-6454656\n",
      "\n",
      "Consideration\n",
      "- You must follow the rules of the mathematics for calling the tool sequentially. If you have to perform a division, you must first perform obtian the \n",
      "values in the numerator and denominator. and then perform the division.\n",
      "\n",
      "When users ask vague questions, ask for clarification. Be conversational and helpful.\n",
      "Always format your responses clearly, using bullet points or numbered lists when showing multiple items.\n",
      "You only must show the result of the operation as final answer. Not show the process to get the result.\n",
      "Your answer always must be in Spanish.\n",
      "\n",
      "\n",
      "Messages: [SystemMessage(content=\"You are a helpful assistant that can perform basic arithmetic operations.\\n\\nKey capabilities:\\n- Perform multiplication\\n- Perform division\\n- Perform addition\\n- Perform subtraction\\n\\nThe tool you should use is:\\n- multiply: Multiplies two numbers. The arguments should be passed as 'a' and 'b'. Must not be like arg1: 2422*6454656\\n- divide: Divides two numbers. The arguments should be passed as 'a' and 'b'. Must not be like arg1: 2422/6454656\\n- sum: Sums two numbers. The arguments should be passed as 'a' and 'b'. Must not be like arg1: 2422+6454656\\n- sub: Subtracts two numbers. The arguments should be passed as 'a' and 'b'. Must not be like arg1: 2422-6454656\\n\\nConsideration\\n- You must follow the rules of the mathematics for calling the tool sequentially. If you have to perform a division, you must first perform obtian the \\nvalues in the numerator and denominator. and then perform the division.\\n\\nWhen users ask vague questions, ask for clarification. Be conversational and helpful.\\nAlways format your responses clearly, using bullet points or numbered lists when showing multiple items.\\nYou only must show the result of the operation as final answer. Not show the process to get the result.\\nYour answer always must be in Spanish.\\n\\n\", additional_kwargs={}, response_metadata={}), HumanMessage(content='Cual es el resultado de (1645+1223)/344', additional_kwargs={}, response_metadata={})]\n",
      "Processing 1 tool calls\n",
      "Processing tool call: sum\n",
      "{'name': 'sum', 'args': {'__arg1': '1645', '__arg2': '1223'}, 'id': 'call_kSSObQgYyoVpWUlsPutoH6Tw', 'type': 'tool_call'}\n",
      "------------------\n",
      "üîç Calling Tool: sum(a=1645, b=1223)\n",
      "ü§ñ Chatbot node: Processing messages...\n",
      "System message content: You are a helpful assistant that can perform basic arithmetic operations.\n",
      "\n",
      "Key capabilities:\n",
      "- Perform multiplication\n",
      "- Perform division\n",
      "- Perform addition\n",
      "- Perform subtraction\n",
      "\n",
      "The tool you should use is:\n",
      "- multiply: Multiplies two numbers. The arguments should be passed as 'a' and 'b'. Must not be like arg1: 2422*6454656\n",
      "- divide: Divides two numbers. The arguments should be passed as 'a' and 'b'. Must not be like arg1: 2422/6454656\n",
      "- sum: Sums two numbers. The arguments should be passed as 'a' and 'b'. Must not be like arg1: 2422+6454656\n",
      "- sub: Subtracts two numbers. The arguments should be passed as 'a' and 'b'. Must not be like arg1: 2422-6454656\n",
      "\n",
      "Consideration\n",
      "- You must follow the rules of the mathematics for calling the tool sequentially. If you have to perform a division, you must first perform obtian the \n",
      "values in the numerator and denominator. and then perform the division.\n",
      "\n",
      "When users ask vague questions, ask for clarification. Be conversational and helpful.\n",
      "Always format your responses clearly, using bullet points or numbered lists when showing multiple items.\n",
      "You only must show the result of the operation as final answer. Not show the process to get the result.\n",
      "Your answer always must be in Spanish.\n",
      "\n",
      "\n",
      "Messages: [SystemMessage(content=\"You are a helpful assistant that can perform basic arithmetic operations.\\n\\nKey capabilities:\\n- Perform multiplication\\n- Perform division\\n- Perform addition\\n- Perform subtraction\\n\\nThe tool you should use is:\\n- multiply: Multiplies two numbers. The arguments should be passed as 'a' and 'b'. Must not be like arg1: 2422*6454656\\n- divide: Divides two numbers. The arguments should be passed as 'a' and 'b'. Must not be like arg1: 2422/6454656\\n- sum: Sums two numbers. The arguments should be passed as 'a' and 'b'. Must not be like arg1: 2422+6454656\\n- sub: Subtracts two numbers. The arguments should be passed as 'a' and 'b'. Must not be like arg1: 2422-6454656\\n\\nConsideration\\n- You must follow the rules of the mathematics for calling the tool sequentially. If you have to perform a division, you must first perform obtian the \\nvalues in the numerator and denominator. and then perform the division.\\n\\nWhen users ask vague questions, ask for clarification. Be conversational and helpful.\\nAlways format your responses clearly, using bullet points or numbered lists when showing multiple items.\\nYou only must show the result of the operation as final answer. Not show the process to get the result.\\nYour answer always must be in Spanish.\\n\\n\", additional_kwargs={}, response_metadata={}), HumanMessage(content='Cual es el resultado de (1645+1223)/344', additional_kwargs={}, response_metadata={}), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_kSSObQgYyoVpWUlsPutoH6Tw', 'function': {'arguments': '{\"__arg1\":\"1645\",\"__arg2\":\"1223\"}', 'name': 'sum'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 23, 'prompt_tokens': 613, 'total_tokens': 636, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-2025-04-14', 'system_fingerprint': 'fp_3502f4eb73', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--ee634d49-0799-4e26-a154-d3d2f25ef491-0', tool_calls=[{'name': 'sum', 'args': {'__arg1': '1645', '__arg2': '1223'}, 'id': 'call_kSSObQgYyoVpWUlsPutoH6Tw', 'type': 'tool_call'}], usage_metadata={'input_tokens': 613, 'output_tokens': 23, 'total_tokens': 636, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content='2868.0', tool_call_id='call_kSSObQgYyoVpWUlsPutoH6Tw')]\n",
      "Processing 1 tool calls\n",
      "Processing tool call: divide\n",
      "{'name': 'divide', 'args': {'__arg1': '2868', '__arg2': '344'}, 'id': 'call_mPtajg8l2OtnIas3LbXqJzDN', 'type': 'tool_call'}\n",
      "------------------\n",
      "üîç Calling Tool: divide(a=2868, b=344)\n",
      "ü§ñ Chatbot node: Processing messages...\n",
      "System message content: You are a helpful assistant that can perform basic arithmetic operations.\n",
      "\n",
      "Key capabilities:\n",
      "- Perform multiplication\n",
      "- Perform division\n",
      "- Perform addition\n",
      "- Perform subtraction\n",
      "\n",
      "The tool you should use is:\n",
      "- multiply: Multiplies two numbers. The arguments should be passed as 'a' and 'b'. Must not be like arg1: 2422*6454656\n",
      "- divide: Divides two numbers. The arguments should be passed as 'a' and 'b'. Must not be like arg1: 2422/6454656\n",
      "- sum: Sums two numbers. The arguments should be passed as 'a' and 'b'. Must not be like arg1: 2422+6454656\n",
      "- sub: Subtracts two numbers. The arguments should be passed as 'a' and 'b'. Must not be like arg1: 2422-6454656\n",
      "\n",
      "Consideration\n",
      "- You must follow the rules of the mathematics for calling the tool sequentially. If you have to perform a division, you must first perform obtian the \n",
      "values in the numerator and denominator. and then perform the division.\n",
      "\n",
      "When users ask vague questions, ask for clarification. Be conversational and helpful.\n",
      "Always format your responses clearly, using bullet points or numbered lists when showing multiple items.\n",
      "You only must show the result of the operation as final answer. Not show the process to get the result.\n",
      "Your answer always must be in Spanish.\n",
      "\n",
      "\n",
      "Messages: [SystemMessage(content=\"You are a helpful assistant that can perform basic arithmetic operations.\\n\\nKey capabilities:\\n- Perform multiplication\\n- Perform division\\n- Perform addition\\n- Perform subtraction\\n\\nThe tool you should use is:\\n- multiply: Multiplies two numbers. The arguments should be passed as 'a' and 'b'. Must not be like arg1: 2422*6454656\\n- divide: Divides two numbers. The arguments should be passed as 'a' and 'b'. Must not be like arg1: 2422/6454656\\n- sum: Sums two numbers. The arguments should be passed as 'a' and 'b'. Must not be like arg1: 2422+6454656\\n- sub: Subtracts two numbers. The arguments should be passed as 'a' and 'b'. Must not be like arg1: 2422-6454656\\n\\nConsideration\\n- You must follow the rules of the mathematics for calling the tool sequentially. If you have to perform a division, you must first perform obtian the \\nvalues in the numerator and denominator. and then perform the division.\\n\\nWhen users ask vague questions, ask for clarification. Be conversational and helpful.\\nAlways format your responses clearly, using bullet points or numbered lists when showing multiple items.\\nYou only must show the result of the operation as final answer. Not show the process to get the result.\\nYour answer always must be in Spanish.\\n\\n\", additional_kwargs={}, response_metadata={}), HumanMessage(content='Cual es el resultado de (1645+1223)/344', additional_kwargs={}, response_metadata={}), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_kSSObQgYyoVpWUlsPutoH6Tw', 'function': {'arguments': '{\"__arg1\":\"1645\",\"__arg2\":\"1223\"}', 'name': 'sum'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 23, 'prompt_tokens': 613, 'total_tokens': 636, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-2025-04-14', 'system_fingerprint': 'fp_3502f4eb73', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--ee634d49-0799-4e26-a154-d3d2f25ef491-0', tool_calls=[{'name': 'sum', 'args': {'__arg1': '1645', '__arg2': '1223'}, 'id': 'call_kSSObQgYyoVpWUlsPutoH6Tw', 'type': 'tool_call'}], usage_metadata={'input_tokens': 613, 'output_tokens': 23, 'total_tokens': 636, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content='2868.0', tool_call_id='call_kSSObQgYyoVpWUlsPutoH6Tw'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_mPtajg8l2OtnIas3LbXqJzDN', 'function': {'arguments': '{\"__arg1\":\"2868\",\"__arg2\":\"344\"}', 'name': 'divide'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 22, 'prompt_tokens': 647, 'total_tokens': 669, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-2025-04-14', 'system_fingerprint': 'fp_3502f4eb73', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--4f2cef60-ddce-4d22-a560-bc2b9719085f-0', tool_calls=[{'name': 'divide', 'args': {'__arg1': '2868', '__arg2': '344'}, 'id': 'call_mPtajg8l2OtnIas3LbXqJzDN', 'type': 'tool_call'}], usage_metadata={'input_tokens': 647, 'output_tokens': 22, 'total_tokens': 669, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content='8.337209302325581', tool_call_id='call_mPtajg8l2OtnIas3LbXqJzDN')]\n",
      "‚úÖ Conversation complete\n",
      "üìã Final result has 7 messages\n",
      "[AIMessage(content='El resultado es 8.34.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 683, 'total_tokens': 692, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-2025-04-14', 'system_fingerprint': 'fp_3502f4eb73', 'finish_reason': 'stop', 'logprobs': None}, id='run--fb7c79fe-1f54-449c-840c-e431da5f6129-0', usage_metadata={'input_tokens': 683, 'output_tokens': 9, 'total_tokens': 692, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_mPtajg8l2OtnIas3LbXqJzDN', 'function': {'arguments': '{\"__arg1\":\"2868\",\"__arg2\":\"344\"}', 'name': 'divide'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 22, 'prompt_tokens': 647, 'total_tokens': 669, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-2025-04-14', 'system_fingerprint': 'fp_3502f4eb73', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--4f2cef60-ddce-4d22-a560-bc2b9719085f-0', tool_calls=[{'name': 'divide', 'args': {'__arg1': '2868', '__arg2': '344'}, 'id': 'call_mPtajg8l2OtnIas3LbXqJzDN', 'type': 'tool_call'}], usage_metadata={'input_tokens': 647, 'output_tokens': 22, 'total_tokens': 669, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_kSSObQgYyoVpWUlsPutoH6Tw', 'function': {'arguments': '{\"__arg1\":\"1645\",\"__arg2\":\"1223\"}', 'name': 'sum'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 23, 'prompt_tokens': 613, 'total_tokens': 636, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-2025-04-14', 'system_fingerprint': 'fp_3502f4eb73', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--ee634d49-0799-4e26-a154-d3d2f25ef491-0', tool_calls=[{'name': 'sum', 'args': {'__arg1': '1645', '__arg2': '1223'}, 'id': 'call_kSSObQgYyoVpWUlsPutoH6Tw', 'type': 'tool_call'}], usage_metadata={'input_tokens': 613, 'output_tokens': 23, 'total_tokens': 636, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\n"
     ]
    }
   ],
   "source": [
    "import uuid\n",
    "\n",
    "# Generate a unique session ID\n",
    "session_id = str(uuid.uuid4())\n",
    "user_str = \"default_user\"\n",
    "message = df['question'][0]\n",
    "app = build_graph()\n",
    "\n",
    "\n",
    "tracer = LangChainTracer()\n",
    "thread = {\n",
    "    \"configurable\": {\n",
    "        \"thread_id\": session_id,\n",
    "    }\n",
    "}\n",
    "\n",
    "thread[\"callbacks\"] = [tracer]\n",
    "thread[\"tracing_v2_enabled\"] = True\n",
    "\n",
    "# Process the chat history to ensure proper structure\n",
    "messages = []\n",
    "tool_call_message = None  # Track the last message with tool_calls\n",
    "\n",
    "# Add the current user message\n",
    "messages.append(HumanMessage(content=message))\n",
    "\n",
    "# Create initial state with messages and user\n",
    "initial_state = StatusMessagesState(\n",
    "    messages=messages,\n",
    "    user=user_str\n",
    ")\n",
    "\n",
    "result = app.invoke(initial_state, config=thread)\n",
    "print(f\"üìã Final result has {len(result['messages'])} messages\")\n",
    "\n",
    "total_result = []\n",
    "# Find the last AI message and check if it has tool calls\n",
    "for msg in reversed(result[\"messages\"]):\n",
    "    if isinstance(msg, AIMessage):\n",
    "        total_result.append(msg)\n",
    "\n",
    "print(total_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AIMessage(content='El resultado es 8.34.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 683, 'total_tokens': 692, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-2025-04-14', 'system_fingerprint': 'fp_3502f4eb73', 'finish_reason': 'stop', 'logprobs': None}, id='run--fb7c79fe-1f54-449c-840c-e431da5f6129-0', usage_metadata={'input_tokens': 683, 'output_tokens': 9, 'total_tokens': 692, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_mPtajg8l2OtnIas3LbXqJzDN', 'function': {'arguments': '{\"__arg1\":\"2868\",\"__arg2\":\"344\"}', 'name': 'divide'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 22, 'prompt_tokens': 647, 'total_tokens': 669, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-2025-04-14', 'system_fingerprint': 'fp_3502f4eb73', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--4f2cef60-ddce-4d22-a560-bc2b9719085f-0', tool_calls=[{'name': 'divide', 'args': {'__arg1': '2868', '__arg2': '344'}, 'id': 'call_mPtajg8l2OtnIas3LbXqJzDN', 'type': 'tool_call'}], usage_metadata={'input_tokens': 647, 'output_tokens': 22, 'total_tokens': 669, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_kSSObQgYyoVpWUlsPutoH6Tw', 'function': {'arguments': '{\"__arg1\":\"1645\",\"__arg2\":\"1223\"}', 'name': 'sum'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 23, 'prompt_tokens': 613, 'total_tokens': 636, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-2025-04-14', 'system_fingerprint': 'fp_3502f4eb73', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--ee634d49-0799-4e26-a154-d3d2f25ef491-0', tool_calls=[{'name': 'sum', 'args': {'__arg1': '1645', '__arg2': '1223'}, 'id': 'call_kSSObQgYyoVpWUlsPutoH6Tw', 'type': 'tool_call'}], usage_metadata={'input_tokens': 613, 'output_tokens': 23, 'total_tokens': 636, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Cual es el resultado de (1645+1223)/344', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_kSSObQgYyoVpWUlsPutoH6Tw', 'function': {'arguments': '{\"__arg1\":\"1645\",\"__arg2\":\"1223\"}', 'name': 'sum'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 23, 'prompt_tokens': 613, 'total_tokens': 636, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-2025-04-14', 'system_fingerprint': 'fp_3502f4eb73', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--ee634d49-0799-4e26-a154-d3d2f25ef491-0', tool_calls=[{'name': 'sum', 'args': {'__arg1': '1645', '__arg2': '1223'}, 'id': 'call_kSSObQgYyoVpWUlsPutoH6Tw', 'type': 'tool_call'}], usage_metadata={'input_tokens': 613, 'output_tokens': 23, 'total_tokens': 636, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_mPtajg8l2OtnIas3LbXqJzDN', 'function': {'arguments': '{\"__arg1\":\"2868\",\"__arg2\":\"344\"}', 'name': 'divide'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 22, 'prompt_tokens': 647, 'total_tokens': 669, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-2025-04-14', 'system_fingerprint': 'fp_3502f4eb73', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--4f2cef60-ddce-4d22-a560-bc2b9719085f-0', tool_calls=[{'name': 'divide', 'args': {'__arg1': '2868', '__arg2': '344'}, 'id': 'call_mPtajg8l2OtnIas3LbXqJzDN', 'type': 'tool_call'}], usage_metadata={'input_tokens': 647, 'output_tokens': 22, 'total_tokens': 669, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       " AIMessage(content='El resultado es 8.34.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 683, 'total_tokens': 692, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-2025-04-14', 'system_fingerprint': 'fp_3502f4eb73', 'finish_reason': 'stop', 'logprobs': None}, id='run--fb7c79fe-1f54-449c-840c-e431da5f6129-0', usage_metadata={'input_tokens': 683, 'output_tokens': 9, 'total_tokens': 692, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_result_reversed = total_result[::-1]\n",
    "total_result_reversed.insert(0, HumanMessage(content=message))\n",
    "total_result_reversed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metricas de RAGAS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RAGAS es una libreria en python para evaluar chatbots tanto de RAG como agenticos. Esta libreria consta de distintas metricas para poder evaluar la perfomances de los chabot, usando LLM como evaluador.\n",
    "\n",
    "El link de esta libreria se encuentra en https://docs.ragas.io/en/stable/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los chatbot con agentes podrian ser evaluado por dos metricas: \n",
    "\n",
    "1. Tool Accuracy: Precision en la ejecucion de los tools. El modelo deberia llamar al tool cuando sea necesario. \n",
    "2. Agent Goal accuracy: Precision en la ejecucion del objetivo del agente. El agente deberia cumplir con el objetivo. Esta metrica podria ser como la accuracy de cualquier modelo de ML, y se estudiara la metrica de precision de NVIDIA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tool Accuracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.metrics import ToolCallAccuracy\n",
    "from ragas.dataset_schema import MultiTurnSample\n",
    "from ragas.integrations.langgraph import convert_to_ragas_messages\n",
    "import ragas.messages as r\n",
    "\n",
    "ragas_trace = convert_to_ragas_messages(\n",
    "    messages=total_result_reversed\n",
    ")  # List of Ragas messages converted using the Ragas function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Cual es el resultado de (1645+1223)/344', metadata=None, type='human'),\n",
       " AIMessage(content='', metadata=None, type='ai', tool_calls=[ToolCall(name='sum', args={'__arg1': '1645', '__arg2': '1223'})]),\n",
       " AIMessage(content='', metadata=None, type='ai', tool_calls=[ToolCall(name='divide', args={'__arg1': '2868', '__arg2': '344'})]),\n",
       " AIMessage(content='El resultado es 8.34.', metadata=None, type='ai', tool_calls=[])]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ragas_trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ragas.metrics import ToolCallAccuracy\n",
    "from ragas.dataset_schema import  MultiTurnSample\n",
    "from ragas.messages import HumanMessage,AIMessage,ToolMessage,ToolCall\n",
    "\n",
    "sample = MultiTurnSample(\n",
    "    user_input=ragas_trace,\n",
    "    reference_tool_calls=df['tool_calls'][0]\n",
    ")\n",
    "\n",
    "scorer = ToolCallAccuracy()\n",
    "await scorer.multi_turn_ascore(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Agent Goal accuracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La respuesta es: El resultado de la operacion es el siguiente: 8.34\n"
     ]
    }
   ],
   "source": [
    "print('La respuesta es: ' + df['result'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from ragas.dataset_schema import MultiTurnSample\n",
    "from ragas.messages import HumanMessage, AIMessage, ToolMessage, ToolCall\n",
    "from ragas.metrics import AgentGoalAccuracyWithReference\n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "\n",
    "# 1Ô∏è‚É£ Define the evaluator LLM\n",
    "evaluator_llm = LangchainLLMWrapper(ChatOpenAI(model=\"gpt-4.1-mini\"))\n",
    "\n",
    "# 2Ô∏è‚É£ Create your MultiTurnSample\n",
    "sample = MultiTurnSample(\n",
    "    user_input=ragas_trace,\n",
    "    reference=df['result'][0]\n",
    ")\n",
    "\n",
    "# 3Ô∏è‚É£ Create the scorer with the evaluator_llm\n",
    "scorer = AgentGoalAccuracyWithReference(llm=evaluator_llm)\n",
    "\n",
    "# 4Ô∏è‚É£ Run the evaluation\n",
    "result = await scorer.multi_turn_ascore(sample)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta correcto, pero que pasa si lo dejamos con todos los numeros decimales, el resultado cambia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_redefined = 'El resultado de la operacion es el siguiente: 8.33720'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# 1Ô∏è‚É£ Define the evaluator LLM\n",
    "evaluator_llm = LangchainLLMWrapper(ChatOpenAI(model=\"gpt-4.1-mini\"))\n",
    "\n",
    "# 2Ô∏è‚É£ Create your MultiTurnSample\n",
    "sample = MultiTurnSample(\n",
    "    user_input=ragas_trace,\n",
    "    reference=reference_redefined\n",
    ")\n",
    "\n",
    "# 3Ô∏è‚É£ Create the scorer with the evaluator_llm\n",
    "scorer = AgentGoalAccuracyWithReference(llm=evaluator_llm)\n",
    "\n",
    "# 4Ô∏è‚É£ Run the evaluation\n",
    "result = await scorer.multi_turn_ascore(sample)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer Accuracy (NVIDIA metrics)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'El resultado es 8.34.'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ragas_trace[-1].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n"
     ]
    }
   ],
   "source": [
    "from ragas.dataset_schema import SingleTurnSample\n",
    "from ragas.metrics import AnswerAccuracy\n",
    "\n",
    "sample = SingleTurnSample(\n",
    "    user_input=message,\n",
    "    response=ragas_trace[-1].content,\n",
    "    reference=\"El resultado de de la operacion es 8.337\"\n",
    ")\n",
    "scorer = AnswerAccuracy(llm=evaluator_llm) # evaluator_llm wrapped with ragas LLM Wrapper\n",
    "score = await scorer.single_turn_ascore(sample)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
